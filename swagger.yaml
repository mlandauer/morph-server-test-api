# Example YAML to get you started quickly.
# Be aware that YAML has indentation based scoping.
# Code completion support is available so start typing for available options.
swagger: '2.0'

# This is your document metadata
info:
  version: "0.0.1"
  title: A straw-man for the morph server API
  description: |
    Some initial straw-man documentation for the morph server,
    a low level scraper api, suggested in
    https://github.com/openaustralia/morph/issues/647

securityDefinitions:
  api_key:
    type: apiKey
    name: api_key
    in: header

# Describe your paths here
paths:
  # This is a path endpoint. Change it.
  /runs:
    # This is a HTTP operation
    post:
      summary: Start a scraper run
      # Describe this verb here. Note: you can use markdown
      description: |
        Actually start a scraper. Give it the scraper code (in any language supported
        by buildstep) and any associated data it needs locally. This will return as
        soon as the scraper is compiling and/or running with the "run ID" which
        uniquelly identifies this scraper run. You will need this run ID to
        subsequently track and access this scraper.
      # This is array of GET operation parameters:
      consumes:
        - multipart/form-data
      parameters:
        -
          name: code
          in: formData
          description: |
            Directory with code, configuration and data to run. Everything needs
            to be tarred up.
          required: true
          type: file
        -
          name: environment
          in: formData
          description: |
            Environment variables to set for the scraper run. Each environment
            should be passed in the form `VARIABLE=VALUE`.
          type: array
          items:
            type: string
      schemes: 
        - https
      security:
        -
          api_key: []
      # Expected responses for this operation:
      responses:
        # Response code
        200:
          description: Started successfully
          # A schema describing your response object.
          # Use JSON Schema format
          schema:
            title: run_id
            type: integer
            description: |
              Uniquelly identifies this scraper run. Needed for any subsequent API calls
              for this run.
  /runs/{id}/events:
    get:
      summary: Attach to scraper event stream
      description: |
        Watch what is happening to a scraper in real-time as it gets compiled and runs.
        By default this will stream all events that have occurred from the scraper
        getting started until now and then as new events occur stream those in real-time.
        If for any reason this connection dies (or you stop it), you can reconnect with
        the last successfully received event ID and the stream will start from the next
        event.

        Note that even if a scraper has completed or failed calling this should succeed.
        As in it should be possible to get the whole event log of everything that happened
        even if nothing is currently running.
        
        **TODO**: Figure out how to represent JSON streams in swagger in response below
      parameters:
        -
          name: id
          in: path
          description: The event ID (as returned by starting a scraper run)
          type: integer
          required: true
      responses:
        200:
          description: Attached
          schema:
            type: array
            items:
              $ref: '#/definitions/Event'

definitions:
  Event:
    type: object
    discriminator: type
    properties:
      id:
        type: integer
      type:
        type: string
      time:
        type: string
        format: date-time
        description: Date and time of event
      stage:
        type: string
        description: Whether this event happened in compile or run stage
        enum:
          - queued
          - compiling
          - running
          - stopped
    required:
      - id
      - type
      - time
      - stage
    
  LogEvent:
    type: object
    description: Console output event (from scraper run)
    allOf:
    - $ref: '#/definitions/Event'
    - type: object
      properties:
        source:
          type: string
          enum: ["stdout", "stderr"]
          description: |
            Source of the message. e.g. `stdout`, `stderr`
        text:
          type: string
          description: Console message
      required:
        - source
        - text
        
  ConnectionEvent:
    type: object
    description: http/https connection made to the outside world
    allOf:
    - $ref: '#/definitions/Event'
    - type: object
      properties:
        method:
          type: string
          description: REST method used (e.g. GET, PUT..)
        scheme:
          type: string
          description: Whether http or https
        domain:
          type: string
          description: Name of server being connected to
        path:
          type: string
          description: Path bit of url from domain being connected to
        request_size:
          type: integer
        response_size:
          type: integer
        response_code:
          type: integer
      required:
        - method
        - scheme
        - domain
        - path
        - request_size
        - response_size
        - response_code
  StageChangeEvent:
    type: object
    description: |
      Event for moving from one stage to another. e.g. queued, compiling,
      running, exited with particular exit code. The stage is the stage that
      we're moving into.
    properties:
      exitCode:
        type: integer
        description: |
          On stage "stopped", includes the exitCode of the
          running process.
        
      
    